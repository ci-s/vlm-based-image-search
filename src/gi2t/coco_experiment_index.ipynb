{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/prakt/s0077/miniconda3/envs/image-search/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from pycocotools.coco import COCO\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from services.search import ImageRepresentations, SearchService\n",
    "from eval.metrics import Metrics\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from services.settings import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/prakt/s0077/miniconda3/envs/image-search/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# set parameters\n",
    "k = 10\n",
    "threshold = 0.3\n",
    "last_index = 500\n",
    "\n",
    "options_without_all = [\"first\", \"random\", \"concat\", \"avg_embedding\"] #\n",
    "\n",
    "all_queries_path = os.path.join(settings.project_root_dir,\"src/eval/extended_queries.json\" )\n",
    "all_queries = json.load(open(all_queries_path))\n",
    "response_dict_path = os.path.join(settings.output_dir, \"response_dict_git_\" + str(last_index) +\".json\")\n",
    "\n",
    "encoder_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "url_prefix=\"http://images.cocodataset.org/val2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['birthday cake',\n",
       " 'wooden chair',\n",
       " 'antique pocket watch',\n",
       " 'crystal wine glasses',\n",
       " 'vintage sofa']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_queries[\"categories\"][\"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# COCO RELATED FUNCTIONS\n",
    "def set_coco_object(data_dir):\n",
    "    ann_file = os.path.join(data_dir, 'coco-images/annotations/captions_val2017.json')\n",
    "    coco = COCO(ann_file)\n",
    "    return coco\n",
    "\n",
    "def get_coco_ids_from_filenames(coco, filename_list):\n",
    "    # drop the .jpg and convert to int\n",
    "    filename_list = [int(filename[:-4]) for filename in filename_list]\n",
    "    return filename_list\n",
    "    \n",
    "def get_coco_captions_by_index(coco, image_id):\n",
    "    annIds = coco.getAnnIds(imgIds=image_id)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    captions = [ann['caption'] for ann in anns]\n",
    "    return captions\n",
    "\n",
    "def aggregate_captions(captions,mode):\n",
    "    if mode == \"first\":\n",
    "        return captions[0]\n",
    "    elif mode == \"concat\":\n",
    "        return \" \".join(captions)\n",
    "    elif mode == \"random\":\n",
    "        return random.choice(captions)\n",
    "    elif mode == \"avg_embedding\":\n",
    "        return '/'.join(captions)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode\")\n",
    "\n",
    "def get_aggregated_caption_list(coco, mode, filenames):\n",
    "    ids = get_coco_ids_from_filenames(coco, filenames)\n",
    "    aggregated_caption_list = []\n",
    "    for i in ids:\n",
    "        captions = get_coco_captions_by_index(coco, i)\n",
    "        aggregated_caption_list.append(aggregate_captions(captions, mode))\n",
    "    return aggregated_caption_list\n",
    "\n",
    "# set coco object\n",
    "coco_object = set_coco_object(settings.data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric related functions\n",
    "def get_scores(retrieved_files, gt_retrieved_files, performance_dict):\n",
    "    performance_dict[\"precision\"].append(Metrics.precision(retrieved_files, gt_retrieved_files))\n",
    "    performance_dict[\"recall\"].append(Metrics.recall(retrieved_files, gt_retrieved_files))\n",
    "    performance_dict[\"f1\"].append(Metrics.f1_score(retrieved_files, gt_retrieved_files))\n",
    "    performance_dict[\"nDCG\"].append(Metrics.ndcg(retrieved_files, gt_retrieved_files, 5))\n",
    "    performance_dict[\"mRR\"].append(Metrics.mrr(retrieved_files, gt_retrieved_files))\n",
    "    return performance_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index created with 500 sentences\n",
      "Index created with 500 sentences\n"
     ]
    }
   ],
   "source": [
    "# set git's search service\n",
    "git_predicted_file = json.load(open(response_dict_path))\n",
    "filenames = list(git_predicted_file.keys())\n",
    "git_image_representions = ImageRepresentations(filenames=filenames,\n",
    "                                               representations=list(git_predicted_file.values()), \n",
    "                                               url_prefix=url_prefix)\n",
    "\n",
    "git_ss_k = SearchService(image_representations=git_image_representions, encoder_model=encoder_model, k=10)\n",
    "git_ss_thresh = SearchService(image_representations=git_image_representions, encoder_model=encoder_model, threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index created with 500 sentences\n",
      "Index created with 500 sentences\n",
      "Option first\n",
      "Category: object, Method: k=10\n",
      "{'precision': 0.48, 'recall': 0.48, 'f1': 0.48, 'nDCG': 0.566, 'mRR': 1.0}\n",
      "Category: object, Method: threshold=0.3\n",
      "{'precision': 0.455, 'recall': 0.457, 'f1': 0.45, 'nDCG': 0.746, 'mRR': 0.961}\n",
      "Category: action, Method: k=10\n",
      "{'precision': 0.46, 'recall': 0.46, 'f1': 0.46, 'nDCG': 0.858, 'mRR': 1.0}\n",
      "Category: action, Method: threshold=0.3\n",
      "{'precision': 0.518, 'recall': 0.442, 'f1': 0.467, 'nDCG': 0.891, 'mRR': 0.983}\n",
      "Category: objects_with_count, Method: k=10\n",
      "{'precision': 0.34, 'recall': 0.34, 'f1': 0.34, 'nDCG': 0.713, 'mRR': 1.0}\n",
      "Category: objects_with_count, Method: threshold=0.3\n",
      "{'precision': 0.346, 'recall': 0.326, 'f1': 0.334, 'nDCG': 0.619, 'mRR': 0.879}\n",
      "Category: reasoning, Method: k=10\n",
      "{'precision': 0.34, 'recall': 0.34, 'f1': 0.34, 'nDCG': 0.664, 'mRR': 1.0}\n",
      "Category: reasoning, Method: threshold=0.3\n",
      "{'precision': 0.324, 'recall': 0.291, 'f1': 0.302, 'nDCG': 0.546, 'mRR': 0.786}\n",
      "Category: text_on_image, Method: k=10\n",
      "{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'nDCG': 0.573, 'mRR': 1.0}\n",
      "Category: text_on_image, Method: threshold=0.3\n",
      "{'precision': 0.412, 'recall': 0.48, 'f1': 0.439, 'nDCG': 0.525, 'mRR': 0.767}\n",
      "Index created with 500 sentences\n",
      "Index created with 500 sentences\n",
      "Option random\n",
      "Category: object, Method: k=10\n",
      "{'precision': 0.42, 'recall': 0.42, 'f1': 0.42, 'nDCG': 0.599, 'mRR': 1.0}\n",
      "Category: object, Method: threshold=0.3\n",
      "{'precision': 0.46, 'recall': 0.439, 'f1': 0.443, 'nDCG': 0.731, 'mRR': 0.967}\n",
      "Category: action, Method: k=10\n",
      "{'precision': 0.44, 'recall': 0.44, 'f1': 0.44, 'nDCG': 0.737, 'mRR': 1.0}\n",
      "Category: action, Method: threshold=0.3\n",
      "{'precision': 0.519, 'recall': 0.462, 'f1': 0.484, 'nDCG': 0.818, 'mRR': 1.0}\n",
      "Category: objects_with_count, Method: k=10\n",
      "{'precision': 0.34, 'recall': 0.34, 'f1': 0.34, 'nDCG': 0.655, 'mRR': 1.0}\n",
      "Category: objects_with_count, Method: threshold=0.3\n",
      "{'precision': 0.353, 'recall': 0.365, 'f1': 0.356, 'nDCG': 0.593, 'mRR': 0.842}\n",
      "Category: reasoning, Method: k=10\n",
      "{'precision': 0.4, 'recall': 0.4, 'f1': 0.4, 'nDCG': 0.595, 'mRR': 1.0}\n",
      "Category: reasoning, Method: threshold=0.3\n",
      "{'precision': 0.411, 'recall': 0.331, 'f1': 0.353, 'nDCG': 0.557, 'mRR': 0.79}\n",
      "Category: text_on_image, Method: k=10\n",
      "{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'nDCG': 0.821, 'mRR': 1.0}\n",
      "Category: text_on_image, Method: threshold=0.3\n",
      "{'precision': 0.437, 'recall': 0.522, 'f1': 0.47, 'nDCG': 0.71, 'mRR': 0.756}\n",
      "Index created with 500 sentences\n",
      "Index created with 500 sentences\n",
      "Option concat\n",
      "Category: object, Method: k=10\n",
      "{'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'nDCG': 0.778, 'mRR': 1.0}\n",
      "Category: object, Method: threshold=0.3\n",
      "{'precision': 0.441, 'recall': 0.522, 'f1': 0.469, 'nDCG': 0.774, 'mRR': 0.827}\n",
      "Category: action, Method: k=10\n",
      "{'precision': 0.46, 'recall': 0.46, 'f1': 0.46, 'nDCG': 0.877, 'mRR': 1.0}\n",
      "Category: action, Method: threshold=0.3\n",
      "{'precision': 0.532, 'recall': 0.443, 'f1': 0.475, 'nDCG': 0.884, 'mRR': 0.983}\n",
      "Category: objects_with_count, Method: k=10\n",
      "{'precision': 0.3, 'recall': 0.3, 'f1': 0.3, 'nDCG': 0.672, 'mRR': 1.0}\n",
      "Category: objects_with_count, Method: threshold=0.3\n",
      "{'precision': 0.315, 'recall': 0.3, 'f1': 0.303, 'nDCG': 0.656, 'mRR': 0.845}\n",
      "Category: reasoning, Method: k=10\n",
      "{'precision': 0.34, 'recall': 0.34, 'f1': 0.34, 'nDCG': 0.574, 'mRR': 1.0}\n",
      "Category: reasoning, Method: threshold=0.3\n",
      "{'precision': 0.361, 'recall': 0.277, 'f1': 0.297, 'nDCG': 0.551, 'mRR': 0.793}\n",
      "Category: text_on_image, Method: k=10\n",
      "{'precision': 0.58, 'recall': 0.58, 'f1': 0.58, 'nDCG': 0.697, 'mRR': 1.0}\n",
      "Category: text_on_image, Method: threshold=0.3\n",
      "{'precision': 0.482, 'recall': 0.613, 'f1': 0.498, 'nDCG': 0.641, 'mRR': 0.736}\n",
      "Index created with 500 sentences\n",
      "Index created with 500 sentences\n",
      "Option avg_embedding\n",
      "Category: object, Method: k=10\n",
      "{'precision': 0.54, 'recall': 0.54, 'f1': 0.54, 'nDCG': 0.549, 'mRR': 1.0}\n",
      "Category: object, Method: threshold=0.3\n",
      "{'precision': 0.49, 'recall': 0.618, 'f1': 0.533, 'nDCG': 0.623, 'mRR': 0.801}\n",
      "Category: action, Method: k=10\n",
      "{'precision': 0.56, 'recall': 0.56, 'f1': 0.56, 'nDCG': 0.828, 'mRR': 1.0}\n",
      "Category: action, Method: threshold=0.3\n",
      "{'precision': 0.543, 'recall': 0.697, 'f1': 0.599, 'nDCG': 0.835, 'mRR': 0.827}\n",
      "Category: objects_with_count, Method: k=10\n",
      "{'precision': 0.48, 'recall': 0.48, 'f1': 0.48, 'nDCG': 0.701, 'mRR': 1.0}\n",
      "Category: objects_with_count, Method: threshold=0.3\n",
      "{'precision': 0.394, 'recall': 0.49, 'f1': 0.425, 'nDCG': 0.604, 'mRR': 0.749}\n",
      "Category: reasoning, Method: k=10\n",
      "{'precision': 0.46, 'recall': 0.46, 'f1': 0.46, 'nDCG': 0.749, 'mRR': 1.0}\n",
      "Category: reasoning, Method: threshold=0.3\n",
      "{'precision': 0.394, 'recall': 0.404, 'f1': 0.393, 'nDCG': 0.624, 'mRR': 0.754}\n",
      "Category: text_on_image, Method: k=10\n",
      "{'precision': 0.62, 'recall': 0.62, 'f1': 0.62, 'nDCG': 0.738, 'mRR': 1.0}\n",
      "Category: text_on_image, Method: threshold=0.3\n",
      "{'precision': 0.498, 'recall': 0.692, 'f1': 0.535, 'nDCG': 0.658, 'mRR': 0.702}\n"
     ]
    }
   ],
   "source": [
    "for option in options_without_all:\n",
    "    truth_image_reps = ImageRepresentations(filenames=list(git_predicted_file.keys()),\n",
    "                                                            representations=get_aggregated_caption_list(coco_object, option, filenames), \n",
    "                                                            url_prefix=url_prefix)\n",
    "    truth_ss_k = SearchService(image_representations=truth_image_reps, encoder_model=encoder_model, k=10)\n",
    "    truth_ss_thresh = SearchService(image_representations=truth_image_reps, encoder_model=encoder_model, threshold=0.3)\n",
    "    print(\"Option\", option)\n",
    "    for category in all_queries[\"categories\"].keys():\n",
    "        query_group = all_queries[\"categories\"][category]\n",
    "\n",
    "        # try with k \n",
    "        performance_dict = {\"precision\": [], \"recall\": [], \"f1\": [], \"nDCG\": [], \"mRR\": []}\n",
    "        print(\"Category: %s, Method: k=10\" % (category))\n",
    "        for query in query_group:\n",
    "            retrieved_files = git_ss_k.search(query)\n",
    "            true_retrieved_files = truth_ss_k.search(query)\n",
    "            performance_dict = get_scores(retrieved_files, true_retrieved_files, performance_dict)\n",
    "        avg_performance_dict = {k: sum(v) / len(v) for k, v in performance_dict.items()}\n",
    "        # round all values to 3 decimal places\n",
    "        avg_performance_dict = {k: round(v, 3) for k, v in avg_performance_dict.items()}\n",
    "        print(avg_performance_dict)\n",
    "        \n",
    "        # try with threshold\n",
    "        for query in query_group:\n",
    "            retrieved_files = git_ss_thresh.search(query)\n",
    "            true_retrieved_files = truth_ss_thresh.search(query)\n",
    "            #print(\"Retrived files\", retrieved_files)\n",
    "            #print(\"True retrieved files\", true_retrieved_files)\n",
    "            performance_dict = get_scores(retrieved_files, true_retrieved_files, performance_dict)\n",
    "        avg_performance_dict = {k: sum(v) / len(v) for k, v in performance_dict.items()}\n",
    "        # round all values to 3 decimal places\n",
    "        avg_performance_dict = {k: round(v, 3) for k, v in avg_performance_dict.items()}\n",
    "        print(\"Category: %s, Method: threshold=0.3\" % (category))\n",
    "        print(avg_performance_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
